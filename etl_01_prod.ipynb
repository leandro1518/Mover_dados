{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad777f4-0c54-436b-81ce-58f30a2b34a2",
   "metadata": {},
   "source": [
    "O processo atualiza arquivos CSV em um diretório, adicionando a coluna data_carga com a data de modificação do arquivo. Ele evita sobrescritas desnecessárias ao verificar se a coluna já existe.\n",
    "\n",
    "Um relatório chamado cargas_exec.csv é gerado, detalhando o status de cada arquivo (Atualizado, Já Processado ou Erro), a data de modificação e a data de carga.\n",
    "\n",
    "Arquivos: C:\\Users\\Admin\\Desktop\\CQD\\cargas\n",
    "Relatório: C:\\Users\\Admin\\Desktop\\CQD\\relatorio\\cargas_exec.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c1a29-0bf9-4ed5-8955-d931371799c8",
   "metadata": {},
   "source": [
    "Atualizador de Data de Carga CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86be5d6-dca7-4837-94b9-96e22620b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Importar bibliotecas\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68309c-3ebb-44da-8e39-c03fc24f52f3",
   "metadata": {},
   "source": [
    "Definir diretórios e inicializar variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c244a19-0e58-4c71-993a-786838f4e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Configurações iniciais\n",
    "# Diretório principal contendo os arquivos\n",
    "diretorio_principal = r'C:\\Users\\Admin\\Desktop\\CQD\\cargas'\n",
    "\n",
    "# Local para salvar o relatório\n",
    "diretorio_relatorio = r'C:\\Users\\Admin\\Desktop\\CQD\\relatorio'\n",
    "nome_relatorio = 'cargas_exec.csv'\n",
    "\n",
    "# Lista para armazenar informações dos arquivos processados\n",
    "relatorio_dados = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a6c4a-18a8-43cc-8e4b-fccd9cc00bb2",
   "metadata": {},
   "source": [
    "Percorrer arquivos e processar CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8650fb-c7a1-49ee-a38b-ca92d190ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Processar arquivos CSV\n",
    "# Percorre todas as subpastas e arquivos no diretório\n",
    "for subdir, _, files in os.walk(diretorio_principal):\n",
    "    for file in files:\n",
    "        # Caminho completo do arquivo\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        \n",
    "        # Verifica se o arquivo é CSV\n",
    "        if file.endswith('.csv'):\n",
    "            try:\n",
    "                # Carregar o arquivo CSV\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Verifica se a coluna 'data_carga' já existe\n",
    "                if 'data_carga' not in df.columns:\n",
    "                    # Data de modificação do arquivo\n",
    "                    data_modificacao = datetime.fromtimestamp(os.path.getmtime(file_path)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    \n",
    "                    # Adicionar a coluna 'data_carga'\n",
    "                    df['data_carga'] = data_modificacao\n",
    "                    \n",
    "                    # Salvar o arquivo atualizado\n",
    "                    df.to_csv(file_path, index=False)\n",
    "                    \n",
    "                    # Adicionar informações ao relatório\n",
    "                    relatorio_dados.append({\n",
    "                        'Arquivo': file_path,\n",
    "                        'Status': 'Atualizado',\n",
    "                        'Data de Modificação': data_modificacao,\n",
    "                        'Data de Carga': data_modificacao\n",
    "                    })\n",
    "                    print(f\"Atualizado: {file_path}\")\n",
    "                else:\n",
    "                    # Se a coluna já existir, captura o valor de 'data_carga'\n",
    "                    data_carga = df['data_carga'].iloc[0] if not df['data_carga'].isnull().all() else 'N/A'\n",
    "                    \n",
    "                    relatorio_dados.append({\n",
    "                        'Arquivo': file_path,\n",
    "                        'Status': 'Já Processado',\n",
    "                        'Data de Modificação': 'N/A',\n",
    "                        'Data de Carga': data_carga\n",
    "                    })\n",
    "                    print(f\"A coluna 'data_carga' já existe: {file_path}. Nenhuma alteração foi feita.\")\n",
    "            except Exception as e:\n",
    "                # Adicionar informações de erro ao relatório\n",
    "                relatorio_dados.append({\n",
    "                    'Arquivo': file_path,\n",
    "                    'Status': f\"Erro: {e}\",\n",
    "                    'Data de Modificação': 'N/A',\n",
    "                    'Data de Carga': 'N/A'\n",
    "                })\n",
    "                print(f\"Erro ao processar {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f6a09-3f2b-4898-8ca2-56cf60ba8b07",
   "metadata": {},
   "source": [
    "Criar e salvar o relatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8adc0e-29c7-4280-9cff-7af7a40c558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Criar e salvar relatório\n",
    "# Cria o DataFrame do relatório\n",
    "relatorio_df = pd.DataFrame(relatorio_dados)\n",
    "\n",
    "# Garante que o diretório para o relatório exista\n",
    "os.makedirs(diretorio_relatorio, exist_ok=True)\n",
    "\n",
    "# Caminho completo do relatório\n",
    "relatorio_path = os.path.join(diretorio_relatorio, nome_relatorio)\n",
    "\n",
    "# Salva o relatório em CSV\n",
    "relatorio_df.to_csv(relatorio_path, index=False)\n",
    "print(f\"Relatório salvo em: {relatorio_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1270dd2-08ba-459e-b791-8457df7010c1",
   "metadata": {},
   "source": [
    "Descrição:\n",
    "Este script automatiza o processo de mapeamento das colunas de todos os arquivos CSV localizados em um diretório e suas subpastas. Ele gera um relatório consolidado que contém informações sobre o número de colunas e seus respectivos nomes para cada arquivo.\n",
    "\n",
    "Como Funciona:\n",
    "\n",
    "Percorre todos os arquivos CSV no diretório especificado e suas subpastas.\n",
    "Extrai os nomes das colunas de cada arquivo.\n",
    "Adiciona os dados de mapeamento a uma lista.\n",
    "Gera um relatório consolidado em formato CSV.\n",
    "Campos do Relatório:\n",
    "\n",
    "Arquivo: Caminho completo do arquivo CSV.\n",
    "Quantidade de Colunas: Número total de colunas no arquivo.\n",
    "Colunas: Lista dos nomes das colunas, separados por vírgula.\n",
    "Local de Salvar o Relatório:\n",
    "O relatório será salvo em: C:\\Users\\Admin\\Desktop\\CQD\\relatorio\\mapeamento_colunas.csv.\n",
    "\n",
    "Instruções de Uso:\n",
    "\n",
    "Configure o diretório principal (diretorio_principal) e o local do relatório (diretorio_relatorio).\n",
    "Execute as células do script em sequência no Jupyter Notebook.\n",
    "Verifique o relatório gerado no diretório configurado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d3c0a-caa2-4893-859e-c844eeb7925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Importar Bibliotecas\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3501597-910e-4279-9795-e9a2bf5ec250",
   "metadata": {},
   "source": [
    "Definir Diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f81904-7091-4479-a987-6301ce2c9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Definir Diretórios\n",
    "# Diretório principal contendo os arquivos CSV\n",
    "diretorio_principal = r'C:\\Users\\Admin\\Desktop\\CQD\\cargas'\n",
    "\n",
    "# Local para salvar o relatório\n",
    "diretorio_relatorio = r'C:\\Users\\Admin\\Desktop\\CQD\\relatorio'\n",
    "nome_relatorio = 'mapeamento_colunas.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e0f77-28ce-4113-89a4-b96bfe911bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Carregar Relatório Existente\n",
    "# Verifica se o relatório já existe e carrega os arquivos já verificados\n",
    "caminho_relatorio = os.path.join(diretorio_relatorio, nome_relatorio)\n",
    "\n",
    "if os.path.exists(caminho_relatorio):\n",
    "    df_relatorio_existente = pd.read_csv(caminho_relatorio)\n",
    "    arquivos_verificados = set(df_relatorio_existente['Arquivo'].tolist())\n",
    "    print(f\"Relatório existente carregado. {len(arquivos_verificados)} arquivos ja verificados.\")\n",
    "else:\n",
    "    df_relatorio_existente = pd.DataFrame(columns=['Arquivo', 'Quantidade de Colunas', 'Colunas'])\n",
    "    arquivos_verificados = set()\n",
    "    print(\"Nenhum relatório existente encontrado. Todos os arquivos serão verificados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4d582-90d3-4278-b027-89ebd3d1e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Inicializar Lista de Resultados\n",
    "# Lista para armazenar os resultados do mapeamento\n",
    "mapeamento = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22858c51-b784-4b4b-b36a-1a80b643e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Mapear Colunas dos Arquivos CSV\n",
    "# Percorre todas as subpastas e arquivos no diretório\n",
    "for subdir, _, files in os.walk(diretorio_principal):\n",
    "    for file in files:\n",
    "        # Caminho completo do arquivo\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        \n",
    "        # Verifica se o arquivo já foi processado\n",
    "        if file_path in arquivos_verificados:\n",
    "            print(f\"Arquivo já verificado: {file_path}. Pulando...\")\n",
    "            continue\n",
    "        \n",
    "        # Verifica se o arquivo é CSV\n",
    "        if file.endswith('.csv'):\n",
    "            try:\n",
    "                # Carrega o CSV e captura as colunas\n",
    "                df = pd.read_csv(file_path)\n",
    "                colunas = list(df.columns)\n",
    "                \n",
    "                # Adiciona ao mapeamento\n",
    "                mapeamento.append({\n",
    "                    'Arquivo': file_path,\n",
    "                    'Quantidade de Colunas': len(colunas),\n",
    "                    'Colunas': ', '.join(colunas)\n",
    "                })\n",
    "                print(f\"Arquivo mapeado: {file_path}\")\n",
    "            except Exception as e:\n",
    "                # Adiciona arquivos com erro ao mapeamento\n",
    "                mapeamento.append({\n",
    "                    'Arquivo': file_path,\n",
    "                    'Quantidade de Colunas': 'Erro',\n",
    "                    'Colunas': f\"Erro: {e}\"\n",
    "                })\n",
    "                print(f\"Erro ao processar {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d8428-5522-4076-abe0-1b901fbf9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Atualizar e Salvar Relatório\n",
    "# Cria um DataFrame com o novo mapeamento\n",
    "df_mapeamento = pd.DataFrame(mapeamento)\n",
    "\n",
    "# Combina o relatório existente com os novos resultados\n",
    "df_relatorio_atualizado = pd.concat([df_relatorio_existente, df_mapeamento], ignore_index=True)\n",
    "\n",
    "# Garante que o diretório para salvar o relatório exista\n",
    "os.makedirs(diretorio_relatorio, exist_ok=True)\n",
    "\n",
    "# Salva o relatório atualizado em um arquivo CSV\n",
    "df_relatorio_atualizado.to_csv(caminho_relatorio, index=False)\n",
    "print(f\"Relatório atualizado salvo em: {caminho_relatorio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a1e566-ba93-427a-bc08-aca91aa3c297",
   "metadata": {},
   "source": [
    "Script de Ajuste e Padronização de Arquivos CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c5a8e-892f-440b-9aa8-0374addb8a03",
   "metadata": {},
   "source": [
    "Processa arquivos CSV em um diretório e realiza ajustes para padronizar os nomes das colunas, verificar colunas ausentes ou excedentes, e corrigir valores específicos. Além disso, gera um relatório detalhado com informações sobre os ajustes realizados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1796e3-ed66-49aa-abb6-ff57654b9d5c",
   "metadata": {},
   "source": [
    "Padronização de Colunas:\n",
    "\n",
    "Converte os nomes de todas as colunas para maiúsculas e remove acentos.\n",
    "Renomeia colunas específicas, como DADOS_SENSÍVEIS para DADOS_SENSIVEIS.\n",
    "Preenchimento e Correção de Dados:\n",
    "\n",
    "Preenche valores ausentes em IP_SERVIDOR com os da coluna IP, caso existam.\n",
    "Remove colunas não esperadas ou extras, como IP após o ajuste.\n",
    "Relatório Detalhado:\n",
    "\n",
    "Lista de colunas ausentes e excedentes por arquivo.\n",
    "Número de colunas antes e após os ajustes.\n",
    "Coluna ajustada, se aplicável.\n",
    "Status de cada arquivo (Ajustado ou Erro).\n",
    "Incrementalidade:\n",
    "\n",
    "Não processa novamente arquivos que já foram ajustados, com base em um relatório existente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d51362-df24-46a4-b483-0fa0eca95dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Importação de Bibliotecas\n",
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89737200-a7b8-4953-ae7a-4fff1056e130",
   "metadata": {},
   "source": [
    "Definição de Diretórios e Padrão de Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bc1c8-302e-4274-bae6-1790e9eca95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Definição de Diretórios e Padrão de Colunas\n",
    "\n",
    "# Diretório principal contendo os arquivos CSV\n",
    "diretorio_principal = r'C:\\Users\\Admin\\Desktop\\CQD\\cargas'\n",
    "\n",
    "# Local para salvar o relatório\n",
    "diretorio_relatorio = r'C:\\Users\\Admin\\Desktop\\CQD\\relatorio'\n",
    "nome_relatorio = 'ajuste_padronizacao.csv'\n",
    "\n",
    "# Padrão esperado de colunas\n",
    "colunas_padrao = [\n",
    "    \"NOME_DO_SGBD\", \"IP_SERVIDOR\", \"VERSAO_DO_SGDB\", \"NOME_BANCO\", \"NOME_SCHEMA\",\n",
    "    \"NOME_TABELA\", \"TIPO_CARACTERISTICA\", \"NOME_COLUNA\", \"TIPO_DADO\", \"PERMITE_NULO\",\n",
    "    \"TIPO_DE_CHAVE\", \"TIPO_DE_CAMPO\", \"DADOS_SENSIVEIS\", \"DATA_CARGA\"\n",
    "]\n",
    "\n",
    "# Função para remover acentos\n",
    "def remover_acentos(string):\n",
    "    if not isinstance(string, str):\n",
    "        return string\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', string) if unicodedata.category(c) != 'Mn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad06066-25e1-4c81-adfd-b0a975feafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Carregar Relatório Anterior\n",
    "\n",
    "# Carrega o relatório anterior, se existir\n",
    "relatorio_path = os.path.join(diretorio_relatorio, nome_relatorio)\n",
    "if os.path.exists(relatorio_path):\n",
    "    relatorio_anterior = pd.read_csv(relatorio_path)\n",
    "    arquivos_ajustados = set(relatorio_anterior['Arquivo'].tolist())\n",
    "    print(f\"Relatório existente carregado. {len(arquivos_ajustados)} arquivos já ajustados.\")\n",
    "else:\n",
    "    relatorio_anterior = pd.DataFrame(columns=['Arquivo', 'Status', 'Colunas Faltantes', 'Colunas a Mais', 'Coluna Ajustada', 'Colunas Antes', 'Colunas Depois'])\n",
    "    arquivos_ajustados = set()\n",
    "    print(\"Nenhum relatório existente encontrado. Todos os arquivos serão processados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9d280-3e7f-44eb-bda8-a3df43763909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Inicializar Relatório Novo\n",
    "\n",
    "# Lista para o novo relatório\n",
    "relatorio_dados = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328b602-ed37-480e-8f53-3e795e7fb99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Processar Arquivos CSV\n",
    "\n",
    "# Processa cada arquivo CSV no diretório\n",
    "for subdir, _, files in os.walk(diretorio_principal):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        \n",
    "        # Verifica se o arquivo já foi ajustado\n",
    "        if file_path in arquivos_ajustados:\n",
    "            print(f\"Arquivo já ajustado: {file_path}. Pulando...\")\n",
    "            continue\n",
    "\n",
    "        if file.endswith('.csv'):\n",
    "            try:\n",
    "                # Carregar o arquivo\n",
    "                df = pd.read_csv(file_path)\n",
    "                colunas_antes = len(df.columns)  # Número de colunas antes do ajuste\n",
    "                colunas_atuais = df.columns.tolist()\n",
    "                coluna_ajustada = None\n",
    "\n",
    "                # Identifica colunas a mais (não estão no padrão esperado)\n",
    "                colunas_a_mais = [col for col in colunas_atuais if remover_acentos(col.upper()) not in colunas_padrao]\n",
    "\n",
    "                # Padroniza os nomes das colunas\n",
    "                df.rename(columns=lambda x: remover_acentos(x).upper(), inplace=True)\n",
    "                \n",
    "                # Renomeia \"DADOS_SENSÍVEIS\" para \"DADOS_SENSIVEIS\"\n",
    "                if \"DADOS_SENSÍVEIS\" in df.columns:\n",
    "                    df.rename(columns={\"DADOS_SENSÍVEIS\": \"DADOS_SENSIVEIS\"}, inplace=True)\n",
    "                    coluna_ajustada = \"DADOS_SENSIVEIS\"\n",
    "                \n",
    "                # Preenche IP_SERVIDOR com valores de IP, se necessário\n",
    "                if \"IP_SERVIDOR\" in df.columns and \"IP\" in df.columns:\n",
    "                    df[\"IP_SERVIDOR\"] = df[\"IP_SERVIDOR\"].fillna(df[\"IP\"])\n",
    "                    coluna_ajustada = \"IP_SERVIDOR\"\n",
    "                \n",
    "                # Remove a coluna \"IP\"\n",
    "                if \"IP\" in df.columns:\n",
    "                    df.drop(columns=[\"IP\"], inplace=True)\n",
    "\n",
    "                # Remove colunas extras ou não nomeadas\n",
    "                df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "                # Adiciona colunas faltantes\n",
    "                for col in colunas_padrao:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = None\n",
    "\n",
    "                # Ordena as colunas no padrão esperado\n",
    "                df = df[colunas_padrao]\n",
    "                colunas_depois = len(df.columns)  # Número de colunas após o ajuste\n",
    "\n",
    "                # Salva o arquivo ajustado\n",
    "                df.to_csv(file_path, index=False)\n",
    "                \n",
    "                # Atualiza o relatório\n",
    "                relatorio_dados.append({\n",
    "                    \"Arquivo\": file_path,\n",
    "                    \"Status\": \"Ajustado\",\n",
    "                    \"Colunas Faltantes\": \", \".join(set(colunas_padrao) - set(colunas_atuais)),\n",
    "                    \"Colunas a Mais\": \", \".join(colunas_a_mais),\n",
    "                    \"Coluna Ajustada\": coluna_ajustada if coluna_ajustada else \"Nenhuma\",\n",
    "                    \"Colunas Antes\": colunas_antes,\n",
    "                    \"Colunas Depois\": colunas_depois\n",
    "                })\n",
    "                print(f\"Ajustado: {file_path}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                # Atualiza o relatório com erros\n",
    "                relatorio_dados.append({\n",
    "                    \"Arquivo\": file_path,\n",
    "                    \"Status\": f\"Erro: {e}\",\n",
    "                    \"Colunas Faltantes\": \"N/A\",\n",
    "                    \"Colunas a Mais\": \"N/A\",\n",
    "                    \"Coluna Ajustada\": \"N/A\",\n",
    "                    \"Colunas Antes\": \"N/A\",\n",
    "                    \"Colunas Depois\": \"N/A\"\n",
    "                })\n",
    "                print(f\"Erro ao processar {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0faaa-db98-4460-bb9e-ac37da33be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome: Salvar Relatório Atualizado\n",
    "\n",
    "# Combina o novo relatório com o existente\n",
    "relatorio_atualizado = pd.concat([relatorio_anterior, pd.DataFrame(relatorio_dados)], ignore_index=True)\n",
    "\n",
    "# Garante que o diretório para salvar o relatório exista\n",
    "os.makedirs(diretorio_relatorio, exist_ok=True)\n",
    "\n",
    "# Salva o relatório atualizado\n",
    "relatorio_atualizado.to_csv(relatorio_path, index=False)\n",
    "\n",
    "print(f\"Relatório atualizado salvo em: {relatorio_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b087b-0f53-4e2c-ab45-40064b7f9f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
